{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Informações contidas na base de dados**\n",
    "\n",
    "**Base 1:**\n",
    "1. ID do filme\n",
    "2. título e ano de lançamento\n",
    "\n",
    "**Base 2:**\n",
    "1. Cust_Id: ID do customer que fez a avaliação\n",
    "2. Rating: avaliação (nota)\n",
    "3. Date: data da avaliação\n",
    "4. Movie_Id: ID do filme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código para tratamento dos bancos dados com Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamento do banco de dados da base1 com o nome dos filmes e id de identificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o Spark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando uma sessao Spark\n",
    "spark = SparkSession.builder.appName('pyspark_treatment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca time para pegar os tempos de execucao\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionario para salvar os tempos de execucao para o dataset movies.csv\n",
    "execution_time_spk = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a base de dados dos filmes\n",
    "t1 = time.time()\n",
    "df_movies = spark.read.csv('movies.csv', sep=';', header=False, inferSchema=True)\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['import_time_csv'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a base de dados\n",
    "df_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando coluna de nomes e anos de lancamento misturados\n",
    "# Coluna com nome do filme\n",
    "\n",
    "# Primeiramente precisamos importar o pyspark.sql.functions\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Eliminando os parentes dos valores da coluna dos nomes dos filmes e das datas de lancamento\n",
    "df_movies = df_movies.withColumn(\"_c1\", regexp_replace(df_movies[\"_c1\"], \"\\(|\\)\", \"\"))\n",
    "\n",
    "# Separando coluna com split pela virgula\n",
    "df_movies = df_movies.withColumn('splited_column', split(col('_c1'), ','))\n",
    "\n",
    "# Pegando primeira parte da coluna splitada e criando a coluna com nome do filme\n",
    "t1 = time.time()\n",
    "df_movies = df_movies.withColumn('Movie_Name', col('splited_column')[0])\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['new_column_movie'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando segunda parte da coluna splitada e criando a coluna com ano de lancamento\n",
    "t1 = time.time()\n",
    "df_movies = df_movies.withColumn('Release_Year', col('splited_column')[1])\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['new_column_release_year'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataframe modificado\n",
    "df_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusao da coluna splitada\n",
    "df_movies = df_movies.drop('splited_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusao da coluna inicial (_c1) com nome e data de lancamento\n",
    "t1 = time.time()\n",
    "df_movies = df_movies.drop('_c1')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['remove_initial_column'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização do banco de dados \n",
    "df_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeação da coluna de ID do filme com a mesma nomenclatura da base de dados de avaliações.\n",
    "t1 = time.time()\n",
    "df_movies = df_movies.withColumnRenamed('_c0', 'Movie_Id')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['rename_column_movie'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações sobre o dataframe do banco de dados de filmes.\n",
    "df_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a modificando do tipo de dado da coluna com a data de lançamento.\n",
    "t1 = time.time()\n",
    "df_movies = df_movies.withColumn('Release_Year', to_date(df_movies['Release_Year']))\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['change_type_year'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações sobre o dataframe do banco de dados de filmes.\n",
    "df_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização do dataframe com todas as alterações.\n",
    "df_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se possui dados ausentes.\n",
    "t1 = time.time()\n",
    "column_names = ['Movie_Id', 'Movie_Name', 'Release_Year']\n",
    "for column_name in column_names:\n",
    "    null_count = df_movies.filter(df_movies[column_name].isNull()).count()\n",
    "    print(f'{column_name}\\t{null_count}')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['check_missing_data'] = tempo_exec\n",
    "print(execution_time_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se possui linhas duplicadas na base de dados e removendo\n",
    "t1 = time.time()\n",
    "df_movies_without_duplicates = df_movies.dropDuplicates()\n",
    "duplicated_rows = df_movies.count() - df_movies_without_duplicates.count()\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['check_duplicate_lines'] = tempo_exec\n",
    "print(execution_time_spk)\n",
    "print(f'Linhas duplicadas: {duplicated_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se possui id's duplicados.\n",
    "t1 = time.time()\n",
    "df_without_duplitate_id = df_movies.dropDuplicates(subset=['Movie_Id'])\n",
    "count_df_without_duplitate_id = df_movies.count() - df_without_duplitate_id.count()\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['check_duplicate_lines_ids'] = tempo_exec\n",
    "print(execution_time_spk)\n",
    "print(f'IDs duplicados: {count_df_without_duplitate_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se possui filmes com mesmo nome e mesmo ano de lançamento.\n",
    "t1 = time.time()\n",
    "df_group = df_movies.groupBy(df_movies.Movie_Name, df_movies.Release_Year).agg(count('*').alias('Count'))\n",
    "df_duplicates = df_group.filter(df_group['Count'] > 1)\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['check_duplicate_lines_movie_year'] = tempo_exec\n",
    "print(execution_time_spk)\n",
    "df_duplicates.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo tabela com os registros do filme repetido\n",
    "t1 = time.time()\n",
    "df_duplicates_final = df_duplicates.join(df_movies, \\\n",
    "    on=((df_duplicates.Movie_Name == df_movies.Movie_Name) & \\\n",
    "        (df_duplicates.Release_Year == df_movies.Release_Year)))\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time_spk['duplicate_line_dr_quinn'] = tempo_exec\n",
    "print(execution_time_spk)\n",
    "df_duplicates_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: Apesar de existir dois registros com o mesmo nome (Dr. Quinn) e mesmo ano de lançamento (1993), realizando uma busca na internet, foi verificado que no ano de 1993 foram lançados duas temporadas de Dr. Quinn. Dessa forma, os registros estão se referindo a temporadas diferentes, não sendo considerado um registro duplicado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamento do banco de dados da base2 com as avaliações dos usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dicionario para salvar tempos de execucao\n",
    "execution_time2_spk = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a segunda base de dados\n",
    "t1 = time.time()\n",
    "df_customers_rating = spark.read.csv('customers_rating.csv', sep=';', header=True, inferSchema=True)\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['import_time_csv'] = tempo_exec\n",
    "print(execution_time2_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacao do dataframe\n",
    "df_customers_rating.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se possui dados ausentes.\n",
    "t1 = time.time()\n",
    "null_counts = df_customers_rating.select([count(when(col(c).isNull(), c)).alias(c) for c in df_customers_rating.columns])\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['check_missing_data'] = tempo_exec\n",
    "print(execution_time2_spk)\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações sobre o dataframe. \n",
    "df_customers_rating.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a converteção da coluna de Date para datetime. Importante trabalhar com essa coluna no formato de data.\n",
    "t1 = time.time()\n",
    "df_customers_rating = df_customers_rating.withColumn('Date', to_date(df_customers_rating['Date']))\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['change_type_date'] = tempo_exec\n",
    "print(execution_time2_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacao do dataframe\n",
    "df_customers_rating.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmando a mudança da coluna Date\n",
    "df_customers_rating.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação se possui avaliações duplicadas de clientes, \n",
    "# considerando mesmo id do cliente, id do filme e avaliação\n",
    "t1 = time.time()\n",
    "df2_group = df_customers_rating.groupBy(df_customers_rating.Cust_Id, \\\n",
    "    df_customers_rating.Movie_Id, df_customers_rating.Rating).agg(count('*').alias('Count'))\n",
    "df2_duplicates = df2_group.filter(df2_group['Count'] > 1)\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['check_duplicate_lines_movie_year'] = tempo_exec\n",
    "print(execution_time2_spk)\n",
    "df2_duplicates.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Criando um novo dataframe com join do df_movies e df_customers_rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers_rating.printSchema()\n",
    "df_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como a análise será realizada apenas com os filmes que possuem avaliações de clientes, \n",
    "# será realizado um join considerando a interseção entre as tabelas.\n",
    "t1 = time.time()\n",
    "df_join_movies_rating = df_movies.join(df_customers_rating, \\\n",
    "    on=(df_movies.Movie_Id == df_customers_rating.Movie_Id), \\\n",
    "        how='inner').drop('Movie_Id')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['merge_tables'] = tempo_exec\n",
    "print(execution_time2_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacao do dataframe\n",
    "df_join_movies_rating.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de registros no dataframe\n",
    "df_join_movies_rating.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load dos dados (salvamento)\n",
    "# Delta\n",
    "t1 = time.time()\n",
    "df_join_movies_rating.write.format(\"delta\").mode(\"overwrite\").save('./final_data.delta')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['final_load_delta'] = tempo_exec\n",
    "print(execution_time2_spk)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load dos dados (salvamento)\n",
    "# parquet\n",
    "t1 = time.time()\n",
    "df_join_movies_rating.write.format(\"parquet\").mode(\"overwrite\").save('./final_data.parquet')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['final_load_parquet'] = tempo_exec\n",
    "print(execution_time2_spk)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load dos dados (salvamento)\n",
    "# csv\n",
    "t1 = time.time()\n",
    "df_join_movies_rating.write.format(\"csv\").mode(\"overwrite\").save('./final_data.csv')\n",
    "tempo_exec = time.time() - t1\n",
    "execution_time2_spk['final_load_csv'] = tempo_exec\n",
    "print(execution_time2_spk)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os dicionarios com os tempos de execucao para criar o grafico (formato json)\n",
    "import json\n",
    "\n",
    "with open('execution_time_spk.json', 'w') as f:\n",
    "    json.dump(execution_time_spk, f)\n",
    "\n",
    "with open('execution_time2_spk.json', 'w') as f:\n",
    "    json.dump(execution_time2_spk, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e653313aa5c54a0675bb7f68a7b7b01def7211ef5659725a8367c74650dfa89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
